# CUDOCS - AI-Powered CUDOS Documentation Assistant

CUDOCS is an intelligent chat interface that helps developers navigate and understand CUDOS documentation more effectively. Built with Next.js 13+ and Tailwind CSS, it leverages the power of Llama, an open-source AI model deployed on CUDOS intercloud infrastructure, providing decentralized and efficient AI capabilities.

![CUDOCS Interface](/placeholder.svg?height=400&width=800)

## Features

- ü§ñ AI-powered documentation search and explanations
- ‚ö° Llama model deployed on CUDOS intercloud for decentralized AI
- üåê Distributed computing power through CUDOS network
- üí¨ Real-time chat interface with streaming responses
- üîó Automatic linking to relevant documentation
- üåô Dark mode support
- üì± Fully responsive design
- üëç User feedback system
- üöÄ Built with modern web technologies

## How It Works

CUDOCS leverages the power of decentralized computing through CUDOS intercloud:

1. **Decentralized AI**: The Llama model is deployed across the CUDOS intercloud network, ensuring:
   - Distributed computing resources
   - High availability
   - Scalable performance
   - Decentralized infrastructure

2. **Intercloud Integration**: All AI interactions are processed through CUDOS intercloud, providing:
   - Efficient resource allocation
   - Cost-effective computing
   - Reliable model serving
   - Global accessibility

## Tech Stack

- **Framework:** Next.js 13+ (App Router)
- **Styling:** Tailwind CSS
- **UI Components:** shadcn/ui
- **AI Model:** Llama (deployed on CUDOS intercloud)
- **Infrastructure:** CUDOS intercloud network
- **Typography:** Geist Sans & Inter fonts
- **Icons:** Lucide Icons

## Getting Started

### Prerequisites

- Node.js 18.18 or later
- npm or yarn
- CUDOS intercloud API credentials
- Access to CUDOS network

### Installation

1. Clone the repository:
```bash
git clone https://github.com/tabintel/cudocs.git
cd cudocs
```

2. Install dependencies:
```bash
npm install
```

3. Create a `.env.local` file in the root directory:
```plaintext
CUDOS_INTERCLOUD_ENDPOINT=your_endpoint_here
```

### Development

Run the development server:
```bash
npm run dev
```

Open [http://localhost:3000](http://localhost:3000) in your browser to see the application.

### Build

Create a production build:
```bash
npm run build
npm start
```

## CUDOS Intercloud Integration

CUDOCS demonstrates the power of decentralized AI through CUDOS intercloud:

1. **Model Deployment**
   - Llama model is deployed across CUDOS intercloud nodes
   - Automatic scaling based on demand
   - High availability through distributed infrastructure

2. **API Integration**
   - Secure communication with CUDOS intercloud
   - Efficient resource utilization
   - Real-time response streaming

3. **Benefits**
   - Decentralized computing power
   - Cost-effective AI inference
   - Global accessibility
   - Scalable infrastructure

## Acknowledgments

- Built with [Next.js](https://nextjs.org/)
- UI components from [shadcn/ui](https://ui.shadcn.com/)
- Icons from [Lucide](https://lucide.dev/)
- AI powered by Llama on CUDOS intercloud
- Decentralized infrastructure by CUDOS network